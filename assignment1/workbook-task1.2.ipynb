{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment1/workbook-task1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Modify this cell to add your group name, group number and your names and student IDs\n",
    "\n",
    "Group: 99\n",
    "\n",
    "Authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import xarray as xa\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training/testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (10000, 1000, 9)\n",
      "train_y shape: (10000, 1000)\n",
      "\n",
      "test_x shape: (2000, 1000, 9)\n",
      "test_y shape: (2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_from_url(url):\n",
    "    \"\"\"\n",
    "    Loads a dataset from surfdrive. \n",
    "    \n",
    "    Input:\n",
    "    url: Download link of dataset \n",
    "    \n",
    "    Outputs:\n",
    "    x: Input features in numpy array format\n",
    "    y: Targets/labels in numpy array format\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    dataset = np.load(io.BytesIO(response.content)) \n",
    "    \n",
    "    x, y = np.split(dataset, [9], axis=2)\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "# Downloading may take a while..\n",
    "train_x, train_y = load_dataset_from_url('https://surfdrive.surf.nl/files/index.php/s/gVrTFgSJ1rWl1IN/download')\n",
    "test_x, test_y = load_dataset_from_url('https://surfdrive.surf.nl/files/index.php/s/JR0WXbrzzTAmwEB/download')\n",
    "\n",
    "train_y, test_y = train_y.squeeze(-1), test_y.squeeze(-1)\n",
    "print(f\"train_x shape: {train_x.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\\n\")\n",
    "\n",
    "print(f\"test_x shape: {test_x.shape}\")\n",
    "print(f\"test_y shape: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some of the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-f8663d762773>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m \u001B[0mtraining_data_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[0mplot_training_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining_data_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m;\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-f8663d762773>\u001B[0m in \u001B[0;36mto_df\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m     12\u001B[0m     \"\"\"\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m     \u001B[0mnumpy_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     dataset_df = xa.DataArray(numpy_data, \n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "def to_df(x, y):\n",
    "    \"\"\"\n",
    "    Converts training/testing input features and corresponding labels into\n",
    "    a Pandas Dataframe format\n",
    "    \n",
    "    Inputs:\n",
    "    x: Input features (train or test) in numpy array format\n",
    "    y: Targets/labels (train or test) in numpy array format\n",
    "    \n",
    "    Output:\n",
    "    dataset_df: Train or test data, structered as a table with column names\n",
    "    \"\"\"\n",
    "    \n",
    "    numpy_data = np.concatenate([x,y], axis=2)\n",
    "    \n",
    "    dataset_df = xa.DataArray(numpy_data, \n",
    "                                     dims = ['N', 'frame', 'sensor'],\n",
    "                                     name='training_data')\\\n",
    "                                        .to_dataframe()\\\n",
    "                                        .unstack('sensor')['training_data']\\\n",
    "                                        .reset_index()\n",
    "\n",
    "    column_names = ['tot_acc_x', 'tot_acc_y', 'tot_acc_z', 'body_acc_x', 'body_acc_y',\n",
    "       'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'activity']\n",
    "    \n",
    "    dataset_df = dataset_df.rename(columns = dict(zip(list(dataset_df.columns[2:]), \n",
    "                                                      column_names)))\\\n",
    "                                         .astype({'activity':int})\n",
    "\n",
    "    return dataset_df\n",
    "\n",
    "\n",
    "\n",
    "def plot_training_samples(N, dataset_df):\n",
    "    \"\"\"\n",
    "    Plots samples in test/train dataset\n",
    "    \n",
    "    Inputs \n",
    "    N: Number of samples that will be visualised. \n",
    "    dataset_df: Train or test data, structered as a table with column names. \n",
    "                This tabular structured data can be obtained with `to_df` function.\n",
    "    \"\"\"\n",
    "    \n",
    "    f, axes = plt.subplots(N, 4, figsize=(30, N*7))\n",
    "    axes = iter(axes)\n",
    "\n",
    "    for pid, df_pid in list(dataset_df.groupby('N'))[:N]:\n",
    "\n",
    "        ax_tot_acc, ax_body_acc, ax_body_gyro, ax_activity = tuple(next(axes))\n",
    "\n",
    "        df_pid.plot(x = 'frame', y=['tot_acc_x','tot_acc_y', 'tot_acc_z'], title=f'sample={pid}', ax=ax_tot_acc)\n",
    "        df_pid.plot(x = 'frame', y=['body_acc_x','body_acc_y', 'body_acc_z'], ax=ax_body_acc)\n",
    "        df_pid.plot(x = 'frame', y=['body_gyro_x','body_gyro_y', 'body_gyro_z'], ax=ax_body_gyro)\n",
    "        df_pid.plot(x = 'frame', y=['activity'], ax=ax_activity) \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "training_data_df = to_df(train_x, train_y)\n",
    "\n",
    "plot_training_samples(2, training_data_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Implement the solution to task 2 of assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.rnn = nn.LSTM(input_size=64, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x).permute(0, 2, 1)\n",
    "        x, (_, _) = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_dataLoader: torch.utils.data.Dataset,\n",
    "                 validation_dataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_dataLoader = training_dataLoader\n",
    "        self.validation_dataLoader = validation_dataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def run_trainer(self):\n",
    "        train_losses_total = []\n",
    "        val_losses_total = []\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            self.model.train()  # train mode\n",
    "            train_losses=[]\n",
    "            for batch in self.training_dataLoader:\n",
    "                x, y = batch\n",
    "                input, target = x.to(device=self.device, dtype=torch.float), y.to(self.device) # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target)  # calculate training loss\n",
    "\n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "\n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "\n",
    "            self.model.eval()  # evaluation mode\n",
    "            val_losses = []  # accumulate the losses here\n",
    "\n",
    "            for batch in self.validation_dataLoader:\n",
    "                x, y = batch\n",
    "                input, target = x.to(device=self.device, dtype=torch.float), y.to(device=self.device)  # send to device (GPU or CPU)\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(input)   # one forward pass\n",
    "                    loss = self.criterion(out, target) # calculate validation loss\n",
    "\n",
    "                    loss_value = loss.item()\n",
    "                    val_losses.append(loss_value)\n",
    "\n",
    "            print('Epoch:', epoch)\n",
    "            print('Training loss,', np.mean(train_losses))\n",
    "            print('Validation loss,', np.mean(val_losses))\n",
    "            train_losses_total.append(np.mean(train_losses))\n",
    "            val_losses_total.append(np.mean(val_losses))\n",
    "        plt.plot(range(1, self.epochs + 1), train_losses_total, 'g', label='Training loss')\n",
    "        plt.plot(range(1, self.epochs + 1), val_losses_total, 'b', label='Validation loss')\n",
    "        plt.title('Training and Validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('loss.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 9\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_RNN_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2)\n",
    "train_data = TensorDataset(torch.tensor(train_x), torch.tensor(train_y, dtype=torch.long))\n",
    "val_data = TensorDataset(torch.tensor(val_x), torch.tensor(val_y, dtype=torch.long))\n",
    "test_data = TensorDataset(torch.tensor(test_x), torch.tensor(test_y, dtype=torch.long))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = RNNClassifier(input_size=NUM_FEATURES, hidden_size=HIDDEN_SIZE, num_classes=NUM_CLASSES, num_layers=NUM_RNN_LAYERS).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model=model, device=device, criterion=criterion, optimizer=optimizer, training_dataLoader=train_dataloader, validation_dataLoader=val_dataloader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [04:29<19:25, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training loss, 1.78517034471035\n",
      "Validation loss, 1.7783592200279237\n",
      "Epoch: 1\n",
      "Training loss, 1.7748009389638901\n",
      "Validation loss, 1.772412450313568\n",
      "Epoch: 2\n",
      "Training loss, 1.7702831268310546\n",
      "Validation loss, 1.7694251823425293\n",
      "Epoch: 3\n",
      "Training loss, 1.7675303852558135\n",
      "Validation loss, 1.7671383953094482\n",
      "Epoch: 4\n",
      "Training loss, 1.764882922768593\n",
      "Validation loss, 1.7643097043037415\n",
      "Epoch: 5\n",
      "Training loss, 1.7612110966444015\n",
      "Validation loss, 1.759897322654724\n",
      "Epoch: 6\n",
      "Training loss, 1.7551574289798737\n",
      "Validation loss, 1.7522098350524902\n",
      "Epoch: 7\n",
      "Training loss, 1.7439997911453247\n",
      "Validation loss, 1.7370522689819337\n",
      "Epoch: 8\n",
      "Training loss, 1.7197756427526474\n",
      "Validation loss, 1.7011559534072875\n",
      "Epoch: 9\n",
      "Training loss, 1.6551569545269011\n",
      "Validation loss, 1.597565631866455\n",
      "Epoch: 10\n",
      "Training loss, 1.490955427289009\n",
      "Validation loss, 1.4025187230110168\n",
      "Epoch: 11\n",
      "Training loss, 1.3445367282629013\n",
      "Validation loss, 1.3247045183181763\n",
      "Epoch: 12\n",
      "Training loss, 1.296502473950386\n",
      "Validation loss, 1.291848771572113\n",
      "Epoch: 13\n",
      "Training loss, 1.265453245639801\n",
      "Validation loss, 1.2582567811012269\n",
      "Epoch: 14\n",
      "Training loss, 1.224900990128517\n",
      "Validation loss, 1.203833134174347\n",
      "Epoch: 15\n",
      "Training loss, 1.1566175803542138\n",
      "Validation loss, 1.1556882500648498\n",
      "Epoch: 16\n",
      "Training loss, 1.0983404523134233\n",
      "Validation loss, 1.0719704627990723\n",
      "Epoch: 17\n",
      "Training loss, 1.0517151191830636\n",
      "Validation loss, 1.0618462181091308\n",
      "Epoch: 18\n",
      "Training loss, 1.024233096241951\n",
      "Validation loss, 1.046663773059845\n"
     ]
    }
   ],
   "source": [
    "trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:01<00:00, 42.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        x, y = batch\n",
    "        input, target = x.to(device=device, dtype=torch.float), y.to(device=device)  # send to device (GPU or CPU)\n",
    "        with torch.no_grad():\n",
    "            output = model(input)   # one forward pass\n",
    "            outputs.append(torch.argmax(output, dim=1).cpu().detach().numpy())\n",
    "    return np.vstack(outputs)\n",
    "\n",
    "test_pred = predict(test_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-1fed2601003d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0macc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_pred\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0macc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "acc = np.sum(test_pred == test_y) / (test_y.shape[0] * test_y.shape[1])\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}